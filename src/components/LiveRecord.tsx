import React, { useEffect, useRef, useState, useCallback } from 'react';
import { useNavigate } from 'react-router-dom';
import { EditorContent, useEditor } from '@tiptap/react';
import StarterKit from '@tiptap/starter-kit';
import Placeholder from '@tiptap/extension-placeholder';
import { 
  Mic, 
  MicOff, 
  Square, 
  Play, 
  Settings, 
  Volume2, 
  Wifi, 
  WifiOff,
  AlertTriangle,
  ArrowLeft,
  MessageSquare,
  Save
} from 'lucide-react';
import { 
  createSession, 
  LiveMeetingConnection, 
  SessionCreated,
  updateNote
} from '../lib/api';
import { isAuthenticated, getToken } from '../lib/auth';

type RecordingState = 'idle' | 'preparing' | 'recording' | 'paused' | 'stopped' | 'error';
type ConnectionState = 'disconnected' | 'connecting' | 'connected' | 'error';

interface TranscriptItem {
  id: string;
  text: string;
  timestamp: number;
  speaker?: string;
  confidence?: number;
  is_final?: boolean;
}

const LiveRecord: React.FC = () => {
  const navigate = useNavigate();
  
  // Basic states
  const [recordingState, setRecordingState] = useState<RecordingState>('idle');
  const [connectionState, setConnectionState] = useState<ConnectionState>('disconnected');
  const [isRecordingActive, setIsRecordingActive] = useState(false);
  const [speechRecognitionStarted, setSpeechRecognitionStarted] = useState(false);
  const [serverRecordingConfirmed, setServerRecordingConfirmed] = useState(false);
  const [elapsed, setElapsed] = useState(0);
  const [title, setTitle] = useState('');
  const [hasStarted, setHasStarted] = useState(false);
  
  // Audio states
  const [micPermission, setMicPermission] = useState<'granted' | 'denied' | 'prompt' | 'checking'>('checking');
  const [audioLevel, setAudioLevel] = useState(0);
  const [hasAudioDevices, setHasAudioDevices] = useState(false);
  const [selectedDeviceId, setSelectedDeviceId] = useState<string>('');
  const [audioDevices, setAudioDevices] = useState<MediaDeviceInfo[]>([]);
  
  // Session and WebSocket states
  const [session, setSession] = useState<SessionCreated | null>(null);
  const [wsConnection, setWsConnection] = useState<LiveMeetingConnection | null>(null);
  const wsConnectionRef = useRef<LiveMeetingConnection | null>(null);
  const [transcripts, setTranscripts] = useState<TranscriptItem[]>([]);
  const [connectionStatus, setConnectionStatus] = useState<string>('');
  const [error, setError] = useState<string | null>(null);
  
  // UI states
  const [showSettings, setShowSettings] = useState(false);
  const [isAutoSave, setIsAutoSave] = useState(true);
  const [lastSaved, setLastSaved] = useState<Date | null>(null);
  const editor = useEditor({
    extensions: [
      StarterKit,
      Placeholder.configure({
        placeholder: 'å¯ä»¥åœ¨è¿™é‡Œè®°å½•ä¼šè®®è¿‡ç¨‹ä½ çš„ç¬”è®°ï¼Œæ”¯æŒmarkdownæ ¼å¼',
        emptyEditorClass: 'is-editor-empty',
        includeChildren: true,
      }),
    ],
    content: '',
    editorProps: {
      attributes: {
        class: 'prose prose-invert max-w-none focus:outline-none min-h-[65vh] md:min-h-[72vh]'
      }
    },
  });
  // Refs
  const timerRef = useRef<number | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const mediaRecorderRef = useRef<ScriptProcessorNode | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const transcriptEndRef = useRef<HTMLDivElement>(null);
  const autoSaveTimerRef = useRef<number | null>(null);

  // Authentication check
  useEffect(() => {
    if (!isAuthenticated()) {
      navigate('/app/login');
    }
  }, [navigate]);

  // è®¡ç®—éŸ³é¢‘çº§åˆ«ï¼ˆRMSå€¼ï¼‰
  const calculateAudioLevel = useCallback((pcmData: Int16Array): number => {
    let sum = 0;
    for (let i = 0; i < pcmData.length; i++) {
      sum += pcmData[i] * pcmData[i];
    }
    return Math.sqrt(sum / pcmData.length);
  }, []);

  const sendAudioData = useCallback(async (pcmData: ArrayBuffer) => {
    if (!wsConnection) {
      console.warn('ğŸ”´ WebSocketè¿æ¥ä¸å­˜åœ¨ï¼Œè·³è¿‡éŸ³é¢‘æ•°æ®');
      return;
    }
    
    try {
      // å°† PCM æ•°æ®è½¬æ¢ä¸º base64
      const base64 = btoa(String.fromCharCode(...new Uint8Array(pcmData)));
      console.debug('ğŸµ å‘é€éŸ³é¢‘æ•°æ®:', base64.length, 'å­—ç¬¦');
      
      wsConnection.sendAudioChunk(base64);
    } catch (error) {
      console.error('å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error);
    }
  }, [wsConnection]);

  const setupPCMRecorder = useCallback((stream: MediaStream, audioContext: AudioContext, microphone: MediaStreamAudioSourceNode) => {
    try {
      // ä½¿ç”¨å…±äº«çš„ AudioContext å’Œ microphone
      
      // åˆ›å»ºScriptProcessorNodeæ¥å¤„ç†éŸ³é¢‘æ•°æ®
      const bufferSize = 4096; // ç¼“å†²åŒºå¤§å°
      const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
      
      // PCMæ•°æ®ç¼“å†²åŒº - æŒ‰è…¾è®¯äº‘è¦æ±‚æ¯40mså‘é€1280å­—èŠ‚
      let pcmBuffer: Float32Array[] = [];
      let bufferLength = 0;
      const samplesPerChunk = 640; // 40ms @ 16kHz = 640ä¸ªæ ·æœ¬ = 1280å­—èŠ‚
      
      processor.onaudioprocess = (event) => {
        const inputBuffer = event.inputBuffer;
        const inputData = inputBuffer.getChannelData(0); // è·å–å•å£°é“æ•°æ®
        
        // æ£€æŸ¥è¾“å…¥éŸ³é¢‘æ•°æ®
        const maxInput = Math.max(...Array.from(inputData));
        const minInput = Math.min(...Array.from(inputData));
        const inputLevel = Math.sqrt(Array.from(inputData).reduce((sum, sample) => sum + sample * sample, 0) / inputData.length);
        
        if (inputLevel > 0.001) { // åªæœ‰åœ¨æœ‰éŸ³é¢‘è¾“å…¥æ—¶æ‰è®°å½•
          console.debug('ğŸ¤ éŸ³é¢‘è¾“å…¥æ£€æµ‹:', {
            samples: inputData.length,
            max: maxInput.toFixed(6),
            min: minInput.toFixed(6), 
            level: inputLevel.toFixed(6),
            firstSamples: Array.from(inputData.slice(0, 5)).map(s => s.toFixed(6))
          });
        }
        
        // å¤åˆ¶æ•°æ®åˆ°ç¼“å†²åŒº
        const channelData = new Float32Array(inputData.length);
        channelData.set(inputData);
        pcmBuffer.push(channelData);
        bufferLength += channelData.length;
        
        // å½“ç¼“å†²åŒºè¾¾åˆ°ç›®æ ‡å¤§å°æ—¶å‘é€æ•°æ®ï¼ˆ40msï¼Œç¬¦åˆè…¾è®¯äº‘è¦æ±‚ï¼‰
        while (bufferLength >= samplesPerChunk) {
          // åˆå¹¶ç¼“å†²åŒºä¸­çš„æ•°æ®
          const totalData = new Float32Array(bufferLength);
          let offset = 0;
          for (const buffer of pcmBuffer) {
            totalData.set(buffer, offset);
            offset += buffer.length;
          }
          
          // æå–å‰640ä¸ªæ ·æœ¬ï¼ˆ40msæ•°æ®ï¼‰
          const chunkData = totalData.slice(0, samplesPerChunk);
          
          // è½¬æ¢ä¸º16ä½PCM
          const pcm16 = new Int16Array(chunkData.length);
          for (let i = 0; i < chunkData.length; i++) {
            // å°†float32 (-1åˆ°1) è½¬æ¢ä¸ºint16 (-32768åˆ°32767)
            pcm16[i] = Math.max(-32768, Math.min(32767, Math.round(chunkData[i] * 32767)));
          }
          
          // éŸ³é¢‘æ•°æ®è´¨é‡æ£€æŸ¥
          const audioLevel = calculateAudioLevel(pcm16);
          const isValidAudio = audioLevel > 50; // è®¾ç½®æœ€å°éŸ³é‡é˜ˆå€¼
          
          // åªåœ¨å½•åˆ¶æ¿€æ´»ä¸”æœåŠ¡å™¨ç¡®è®¤åå‘é€æœ‰æ•ˆçš„PCMæ•°æ®
          if (isRecordingActive && serverRecordingConfirmed) {
            if (isValidAudio) {
              // è¯¦ç»†è°ƒè¯•PCMæ•°æ®
              console.debug('ğŸµ å‘é€40mséŸ³é¢‘æ•°æ®ï¼Œæ ·æœ¬æ•°:', pcm16.length, 'éŸ³é‡çº§åˆ«:', audioLevel);
              console.debug('ğŸ” å‰ç«¯PCMé‡‡æ ·ç‚¹ç¤ºä¾‹:', Array.from(pcm16.slice(0, 10)));
              console.debug('ğŸ” åŸå§‹Float32ç¤ºä¾‹:', Array.from(chunkData.slice(0, 10)));
              
              // åˆ›å»ºæ­£ç¡®çš„å­—èŠ‚æ•°ç»„ç¡®ä¿little-endianå­—èŠ‚åº
              const bytes = new Uint8Array(pcm16.length * 2);
              for (let i = 0; i < pcm16.length; i++) {
                const sample = pcm16[i];
                bytes[i * 2] = sample & 0xFF;        // ä½å­—èŠ‚
                bytes[i * 2 + 1] = (sample >> 8) & 0xFF; // é«˜å­—èŠ‚
              }
              
              console.debug('ğŸ” å­—èŠ‚æ•°ç»„å¤´éƒ¨:', Array.from(bytes.slice(0, 20)));
              sendAudioData(bytes.buffer);
            } else {
              console.debug('ğŸ”‡ è·³è¿‡40msé™éŸ³æ•°æ®ï¼ŒéŸ³é‡çº§åˆ«:', audioLevel);
            }
          } else if (isRecordingActive && !serverRecordingConfirmed) {
            console.debug('â³ ç­‰å¾…æœåŠ¡å™¨å½•åˆ¶ç¡®è®¤ä¸­ï¼Œæš‚ä¸å‘é€éŸ³é¢‘æ•°æ®');
          }
          
          // ä¿ç•™å‰©ä½™æ•°æ®ç»§ç»­ä¸‹æ¬¡å¤„ç†
          const remainingData = totalData.slice(samplesPerChunk);
          pcmBuffer = remainingData.length > 0 ? [remainingData] : [];
          bufferLength = remainingData.length;
        }
      };
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      microphone.connect(processor);
      processor.connect(audioContext.destination);
      
      // ä¿å­˜å¼•ç”¨ç”¨äºåœæ­¢
      mediaRecorderRef.current = processor;
      
    } catch (error: unknown) {
      console.error('PCMå½•åˆ¶å™¨è®¾ç½®å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      setError('éŸ³é¢‘å½•åˆ¶å™¨è®¾ç½®å¤±è´¥: ' + errorMessage);
    }
  }, [sendAudioData, isRecordingActive, wsConnection, speechRecognitionStarted, serverRecordingConfirmed, calculateAudioLevel]);

  const requestMicrophoneAccess = useCallback(async (deviceId?: string) => {
    try {
      const constraints = {
        audio: {
          deviceId: deviceId || selectedDeviceId || undefined,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        }
      };
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      setMicPermission('granted');
      setError(null);
      
      // åœæ­¢ä¹‹å‰çš„æµ
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      streamRef.current = stream;
      
      // è®¾ç½®éŸ³é¢‘åˆ†æï¼Œé…ç½®16kHzé‡‡æ ·ç‡
      const audioContext = new AudioContext({ sampleRate: 16000 });
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 256;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      // å¼€å§‹æ£€æµ‹éŸ³é¢‘çº§åˆ«
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const detectAudio = () => {
        if (analyserRef.current) {
          analyserRef.current.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
          setAudioLevel(average);
          requestAnimationFrame(detectAudio);
        }
      };
      detectAudio();
      
      // è®¾ç½® PCM å½•åˆ¶å™¨ï¼Œå…±äº« AudioContext
      setupPCMRecorder(stream, audioContext, microphone);
      
    } catch (error: unknown) {
      console.error('éº¦å…‹é£è®¿é—®è¢«æ‹’ç»:', error);
      setMicPermission('denied');
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      setError('éº¦å…‹é£è®¿é—®å¤±è´¥: ' + errorMessage);
    }
  }, [selectedDeviceId, sendAudioData, isRecordingActive, wsConnection, speechRecognitionStarted, serverRecordingConfirmed, setupPCMRecorder]);

  const checkAudioDevices = useCallback(async () => {
    try {
      // è·å–æ‰€æœ‰è®¾å¤‡
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputDevices = devices.filter(device => device.kind === 'audioinput');
      
      if (audioInputDevices.length === 0) {
        setMicPermission('denied');
        setHasAudioDevices(false);
        setError('æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡');
        return;
      }
      
      setHasAudioDevices(true);
      setAudioDevices(audioInputDevices);
      
      // è®¾ç½®é»˜è®¤è®¾å¤‡
      if (!selectedDeviceId && audioInputDevices.length > 0) {
        setSelectedDeviceId(audioInputDevices[0].deviceId);
      }
      
      // æ£€æŸ¥éº¦å…‹é£æƒé™
      try {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        
        if (permissionStatus.state === 'granted') {
          await requestMicrophoneAccess();
        } else if (permissionStatus.state === 'denied') {
          setMicPermission('denied');
          setError('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®');
        } else {
          setMicPermission('prompt');
        }
      } catch {
        // å¦‚æœæµè§ˆå™¨ä¸æ”¯æŒ permissions APIï¼Œç›´æ¥å°è¯•è¯·æ±‚
        await requestMicrophoneAccess();
      }
    } catch (error: unknown) {
      console.error('éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      setError('éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å¤±è´¥: ' + errorMessage);
      setMicPermission('denied');
    }
  }, [selectedDeviceId, requestMicrophoneAccess]);

  const createNewSession = async () => {
    try {
      setConnectionStatus('åˆ›å»ºä¼šè¯ä¸­...');
      const sessionData = await createSession();
      setSession(sessionData);
      setConnectionStatus('ä¼šè¯åˆ›å»ºæˆåŠŸ');
      return sessionData;
      } catch (error: unknown) {
    console.error('åˆ›å»ºä¼šè¯å¤±è´¥:', error);
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
    setError('åˆ›å»ºä¼šè¯å¤±è´¥: ' + errorMessage);
    setRecordingState('error');
    throw error;
  }
  };

  const connectWebSocket = async (sessionId: string): Promise<LiveMeetingConnection> => {
    try {
      console.log('ğŸ”Œ å¼€å§‹è¿æ¥WebSocket, sessionId:', sessionId);
      setConnectionState('connecting');
      setConnectionStatus('è¿æ¥æœåŠ¡å™¨ä¸­...');
      
      const token = getToken();
      if (!token) {
        throw new Error('æœªæ‰¾åˆ°è®¤è¯ä»¤ç‰Œ');
      }
      
      const connection = new LiveMeetingConnection(sessionId, token);
      
            // åˆ›å»ºPromiseæ¥ç­‰å¾…è¿æ¥å»ºç«‹
      const connectionPromise = new Promise<void>((resolve, reject) => {
        const timeout = setTimeout(() => {
          console.error('ğŸ”´ WebSocketè¿æ¥è¶…æ—¶ï¼Œ10ç§’å†…æœªæ”¶åˆ°connection_ready');
          reject(new Error('WebSocketè¿æ¥è¶…æ—¶ - æœªæ”¶åˆ°connection_readyäº‹ä»¶'));
        }, 10000); // 10ç§’è¶…æ—¶
        
      connection.on('connection_ready', () => {
          console.log('âœ… WebSocket connection_readyäº‹ä»¶å·²æ”¶åˆ°');
        setConnectionState('connected');
        setConnectionStatus('å·²è¿æ¥');
        setError(null);
          clearTimeout(timeout);
          resolve();
        });
        
        connection.on('error', (error: any) => {
          console.error('ğŸ”´ WebSocketè¿æ¥é”™è¯¯:', error);
          clearTimeout(timeout);
          reject(error);
        });
        
                // æ·»åŠ é¢å¤–çš„æ–­å¼€è¿æ¥æ£€æµ‹
        const onDisconnected = () => {
          console.error('ğŸ”´ WebSocketåœ¨å»ºç«‹è¿‡ç¨‹ä¸­æ–­å¼€');
          clearTimeout(timeout);
          connection.off('disconnected', onDisconnected);
          reject(new Error('WebSocketåœ¨å»ºç«‹è¿‡ç¨‹ä¸­æ–­å¼€'));
        };
        connection.on('disconnected', onDisconnected);
      });
      
      connection.on('disconnected', () => {
        console.log('ğŸ”´ WebSocket è¿æ¥æ–­å¼€');
        setConnectionState('disconnected');
        setConnectionStatus('è¿æ¥æ–­å¼€');
      });
      
      // ç›‘å¬è½¬å†™ç»“æœï¼ˆåŒ…æ‹¬å®æ—¶å’Œæœ€ç»ˆç»“æœï¼‰
      connection.on('transcript_partial', (data: Record<string, unknown>) => {
        console.log('æ”¶åˆ°å®æ—¶è½¬å†™ç»“æœ:', data);
        addTranscriptItem(data);
      });
      
      connection.on('transcript_final', (data: Record<string, unknown>) => {
        console.log('æ”¶åˆ°æœ€ç»ˆè½¬å†™ç»“æœ:', data);
        addTranscriptItem(data);
      });
      
      // ç›‘å¬çŠ¶æ€æ›´æ–°
      connection.on('status_update', (data: Record<string, unknown>) => {
        console.log('çŠ¶æ€æ›´æ–°:', data);
        setConnectionStatus(String(data.message) || '');
      });
      
      // ç›‘å¬å½•åˆ¶çŠ¶æ€æ¶ˆæ¯
      connection.on('recording_started', (data: Record<string, unknown>) => {
        console.log('âœ… å½•åˆ¶å·²å¯åŠ¨:', data);
        const message = String(data.message) || 'å½•åˆ¶ä¸­...';
        setConnectionStatus(message);
        setServerRecordingConfirmed(true); // æœåŠ¡å™¨ç¡®è®¤å½•åˆ¶å·²å¼€å§‹
        
        // å»¶è¿Ÿè¿æ¥æˆåŠŸçš„ç‰¹æ®Šæç¤º
        if (data.delayed_connection) {
          console.log('ğŸ‰ å»¶è¿Ÿè¿æ¥æˆåŠŸï¼Œç°åœ¨å¯ä»¥å¼€å§‹è¯´è¯äº†ï¼');
        } else if (data.immediate_connection) {
          console.log('ğŸ‰ è…¾è®¯äº‘è¿æ¥æˆåŠŸï¼Œç°åœ¨å¯ä»¥å¼€å§‹è¯´è¯äº†ï¼');
        }
      });

      connection.on('connection_pending', (data: Record<string, unknown>) => {
        console.log('â³ è¿æ¥å»¶è¿Ÿä¸­:', data);
        setConnectionStatus(String(data.message) || 'æ­£åœ¨è¿æ¥è…¾è®¯äº‘ï¼Œè¯·ç¨å€™...');
        // ä¿æŒç­‰å¾…çŠ¶æ€ï¼Œä¸è®¾ç½®serverRecordingConfirmedä¸ºtrue
        console.log('ğŸ“¢ è¯·ç¨å€™ï¼Œè…¾è®¯äº‘è¿æ¥å»ºç«‹ä¸­ï¼Œæš‚æ—¶ä¸è¦è¯´è¯');
      });
      
      connection.on('recording_stopped', (data: Record<string, unknown>) => {
        console.log('å½•åˆ¶å·²åœæ­¢:', data);
        setConnectionStatus(String(data.message) || 'å½•åˆ¶å·²åœæ­¢');
      });
      
      connection.on('recording_paused', (data: Record<string, unknown>) => {
        console.log('å½•åˆ¶å·²æš‚åœ:', data);
        setConnectionStatus(String(data.message) || 'å½•åˆ¶å·²æš‚åœ');
      });
      
      connection.on('recording_resumed', (data: Record<string, unknown>) => {
        console.log('å½•åˆ¶å·²æ¢å¤:', data);
        setConnectionStatus(String(data.message) || 'å½•åˆ¶ä¸­...');
      });
  
      connection.on('error', (data: Record<string, unknown>) => {
        console.error('ğŸ”´ WebSocket é”™è¯¯:', data);
        const errorCode = String(data.error_code || '');
        const errorMessage = String(data.message) || 'è¿æ¥é”™è¯¯';
        
        if (errorCode === 'AUDIO_FORMAT_ERROR') {
          console.error('ğŸµ éŸ³é¢‘æ ¼å¼é”™è¯¯ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´éŸ³é¢‘é‡‡é›†è®¾ç½®');
          setError('éŸ³é¢‘æ ¼å¼é”™è¯¯ï¼š' + errorMessage);
          // ä¸æ–­å¼€è¿æ¥ï¼Œè®©ç”¨æˆ·é‡æ–°å°è¯•æˆ–è°ƒæ•´è®¾ç½®
        } else {
          setError(errorMessage);
          setConnectionState('error');
        }
      });
      
      console.log('æ­£åœ¨è¿æ¥WebSocket...');
      await connection.connect();
      console.log('WebSocketè¿æ¥æˆåŠŸï¼Œè®¾ç½®è¿æ¥å¯¹è±¡');
      // ç­‰å¾…è¿æ¥å»ºç«‹
      console.log('â³ ç­‰å¾…connection_readyäº‹ä»¶...');
      await connectionPromise;
      console.log('âœ… connection_readyäº‹ä»¶å·²æ”¶åˆ°');
      
      // è¿æ¥å¥åº·æ£€æŸ¥
      console.log('âœ… WebSocketè¿æ¥å°±ç»ªï¼ŒçŠ¶æ€:', connection.ws?.readyState);
      
      setWsConnection(connection);
      wsConnectionRef.current = connection;
      
      return connection; // è¿”å›è¿æ¥å¯¹è±¡
      
      } catch (error: unknown) {
    console.error('ğŸ”´ WebSocket è¿æ¥å¤±è´¥:', error);
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
    setError('WebSocketè¿æ¥å¤±è´¥: ' + errorMessage);
    setConnectionState('error');
    setRecordingState('error');
    throw error; // é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œé˜»æ­¢ start() å‡½æ•°ç»§ç»­æ‰§è¡Œ
  }
  };

  const addTranscriptItem = (transcriptData: Record<string, unknown>) => {
      const newItem: TranscriptItem = {
    id: String(transcriptData.segment_id) || Date.now().toString(),
    text: String(transcriptData.text || ''),
    timestamp: Date.now(),
    speaker: transcriptData.speaker ? String(transcriptData.speaker) : undefined,
    confidence: typeof transcriptData.confidence === 'number' ? transcriptData.confidence : undefined,
    is_final: transcriptData.is_final !== false
  };
    
    setTranscripts(prev => {
      // å¦‚æœæ˜¯ç›¸åŒ ID çš„æ›´æ–°ï¼Œæ›¿æ¢ä¹‹å‰çš„é¡¹
      const existingIndex = prev.findIndex(item => item.id === newItem.id);
      if (existingIndex >= 0) {
        const updated = [...prev];
        updated[existingIndex] = newItem;
        return updated;
      }
      
      // å¦åˆ™æ·»åŠ æ–°é¡¹
      return [...prev, newItem];
    });
    
    // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    setTimeout(() => {
      transcriptEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    }, 100);
  };

    const saveNotes = useCallback(async () => {
    if (!session || !editor) return;
    
    try {
      const content = editor.getHTML();
      await updateNote(session.noteId, {
        title: title || 'å®æ—¶å½•åˆ¶ä¼šè®®',
        content: { user_notes: content }
      });
      setLastSaved(new Date());
      console.log('ç¬”è®°ä¿å­˜æˆåŠŸ');
    } catch (error: unknown) {
      console.error('ä¿å­˜ç¬”è®°å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      setError('ä¿å­˜ç¬”è®°å¤±è´¥: ' + errorMessage);
    }
  }, [session, editor, title]);

  // è‡ªåŠ¨ä¿å­˜åŠŸèƒ½
  useEffect(() => {
    if (!isAutoSave || !hasStarted) return;
    
    if (autoSaveTimerRef.current) {
      clearTimeout(autoSaveTimerRef.current);
    }
    
    autoSaveTimerRef.current = window.setTimeout(() => {
      saveNotes();
    }, 30000); // 30ç§’è‡ªåŠ¨ä¿å­˜
    
    return () => {
      if (autoSaveTimerRef.current) {
        clearTimeout(autoSaveTimerRef.current);
      }
    };
  }, [editor, isAutoSave, hasStarted, saveNotes]);

  const start = async () => {
    if (recordingState === 'recording') return;
    
    try {
      setRecordingState('preparing');
      setError(null);
      
      // åˆ›å»ºä¼šè¯
      const sessionData = await createNewSession();
      
      // è¿æ¥ WebSocket
      const connection = await connectWebSocket(sessionData.sessionId);
      
      // å¼€å§‹å½•éŸ³
      if (mediaRecorderRef.current && streamRef.current) {
        audioChunksRef.current = [];
        setIsRecordingActive(true); // æ¿€æ´»PCMæ•°æ®å‘é€
        
        // é€šçŸ¥æœåŠ¡å™¨å¼€å§‹å½•åˆ¶
        console.log('ğŸš€ å‡†å¤‡å‘é€å½•åˆ¶å¼€å§‹æ¶ˆæ¯ï¼Œä½¿ç”¨è¿æ¥å¯¹è±¡:', !!connection);
        console.log('ğŸš€ WebSocketè¿æ¥å·²å»ºç«‹ï¼Œè°ƒç”¨startRecording');
        
        // æ·»åŠ å°å»¶è¿Ÿç¡®ä¿è¿æ¥å®Œå…¨ç¨³å®š
        await new Promise(resolve => setTimeout(resolve, 100));
        
        const audioConfig = {
          sample_rate: 16000,
          format: 'pcm',
          voice_format: 1,
          engine_type: '16k_zh'
        };
        console.log('ğŸš€ è°ƒç”¨startRecordingï¼Œå‚æ•°:', audioConfig);
        
        connection.startRecording(audioConfig);
        setSpeechRecognitionStarted(true);
        
        console.log('âœ… startRecordingæ¶ˆæ¯å·²å‘é€');
        
        setRecordingState('recording');
    setHasStarted(true);
        
        // å¯åŠ¨è®¡æ—¶å™¨
    timerRef.current = window.setInterval(() => {
      setElapsed((s) => s + 1);
    }, 1000);
        
        setConnectionStatus('å½•åˆ¶ä¸­...');
      } else {
        throw new Error('éŸ³é¢‘è®¾å¤‡æœªå°±ç»ª');
      }
      
      } catch (error: unknown) {
    console.error('ğŸ”´ å¯åŠ¨å½•åˆ¶å¤±è´¥:', error);
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
    setError('å¯åŠ¨å½•åˆ¶å¤±è´¥: ' + errorMessage);
    setRecordingState('error');
    
    // ç¡®ä¿æ¸…ç†è¿æ¥çŠ¶æ€
    setIsRecordingActive(false);
    setSpeechRecognitionStarted(false);
    setServerRecordingConfirmed(false);
    
    // å¦‚æœWebSocketå·²è¿æ¥ï¼Œç¡®ä¿æ–­å¼€è¿æ¥
    if (wsConnection) {
      console.log('ğŸ”´ é”™è¯¯å‘ç”Ÿï¼Œæ–­å¼€WebSocketè¿æ¥');
      wsConnection.disconnect();
      setWsConnection(null);
      wsConnectionRef.current = null;
    }
  }
  };

  const stop = async () => {
    try {
      setRecordingState('stopped');
      
      // åœæ­¢å½•éŸ³
      setIsRecordingActive(false); // åœæ­¢å‘é€PCMæ•°æ®
      setSpeechRecognitionStarted(false); // é‡ç½®è¯­éŸ³è¯†åˆ«çŠ¶æ€
      setServerRecordingConfirmed(false); // é‡ç½®æœåŠ¡å™¨ç¡®è®¤çŠ¶æ€
      if (mediaRecorderRef.current) {
        // æ–­å¼€éŸ³é¢‘èŠ‚ç‚¹è¿æ¥
        try {
          mediaRecorderRef.current.disconnect();
          // AudioContext ä¼šåœ¨ç»„ä»¶æ¸…ç†æ—¶å…³é—­
        } catch (error) {
          console.error('åœæ­¢PCMå½•åˆ¶å™¨å¤±è´¥:', error);
        }
      }
      
      // é€šçŸ¥æœåŠ¡å™¨åœæ­¢å½•åˆ¶
      wsConnection?.stopRecording();
      
      // æ–­å¼€WebSocketè¿æ¥
      if (wsConnection) {
        wsConnection.disconnect();
        setWsConnection(null);
        wsConnectionRef.current = null;
      }
      
      // åœæ­¢è®¡æ—¶å™¨
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      
      // ä¿å­˜æœ€ç»ˆç¬”è®°
      await saveNotes();
      
      setConnectionStatus('å½•åˆ¶å·²åœæ­¢');
      
      // è·³è½¬åˆ°ä¼šè®®è¯¦æƒ…é¡µ
      if (session) {
        navigate(`/app/meetings/${session.sessionId}`);
      }
      
      } catch (error: unknown) {
    console.error('åœæ­¢å½•åˆ¶å¤±è´¥:', error);
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
    setError('åœæ­¢å½•åˆ¶å¤±è´¥: ' + errorMessage);
  }
  };

  const pause = () => {
    if (mediaRecorderRef.current && recordingState === 'recording') {
      setIsRecordingActive(false); // åœæ­¢å‘é€PCMæ•°æ®
      wsConnection?.sendMessage('pause_recording');
      setRecordingState('paused');
      
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    }
  };

  const resume = () => {
    if (mediaRecorderRef.current && recordingState === 'paused') {
      setIsRecordingActive(true); // æ¢å¤å‘é€PCMæ•°æ®
      setSpeechRecognitionStarted(false); // é‡ç½®çŠ¶æ€ï¼Œè®©ä¿é™©æ–¹æ¡ˆé‡æ–°å¯åŠ¨è¯†åˆ«
      setServerRecordingConfirmed(false); // é‡ç½®æœåŠ¡å™¨ç¡®è®¤çŠ¶æ€
      wsConnection?.sendMessage('resume_recording');
      setRecordingState('recording');
      
      timerRef.current = window.setInterval(() => {
        setElapsed((s) => s + 1);
      }, 1000);
    }
  };

  const handleDeviceChange = async (deviceId: string) => {
    setSelectedDeviceId(deviceId);
    if (micPermission === 'granted') {
      await requestMicrophoneAccess(deviceId);
    }
  };

  // åˆå§‹åŒ–å’Œæ¸…ç†
  // ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡
  useEffect(() => {
    checkAudioDevices();
  }, [checkAudioDevices]);
  
  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      console.log('ğŸ§¹ ç»„ä»¶å¸è½½ï¼Œæ¸…ç†èµ„æº');
      // æ¸…ç†å®šæ—¶å™¨
      if (timerRef.current) clearInterval(timerRef.current);
      if (autoSaveTimerRef.current) clearTimeout(autoSaveTimerRef.current);
      
      // æ¸…ç†éŸ³é¢‘è®¾å¤‡
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      
      // æ¸…ç† WebSocket è¿æ¥
      if (wsConnectionRef.current) {
        console.log('ğŸ§¹ ç»„ä»¶å¸è½½æ—¶æ–­å¼€WebSocketè¿æ¥');
        wsConnectionRef.current.disconnect();
      }
    };
  }, []); // ç©ºä¾èµ–æ•°ç»„ï¼Œåªåœ¨ç»„ä»¶å¸è½½æ—¶è¿è¡Œ

  const format = (s: number) => {
    const hh = Math.floor(s / 3600);
    const mm = Math.floor((s % 3600) / 60);
    const ss = s % 60;
    return [hh, mm, ss].map((n) => String(n).padStart(2, '0')).join(':');
  };

  const formatTimestamp = (timestamp: number) => {
    const date = new Date(timestamp);
    return date.toLocaleTimeString();
  };

  const getRecordingStateIcon = () => {
    switch (recordingState) {
      case 'recording':
        return <Mic className="w-5 h-5 text-red-400" />;
      case 'paused':
        return <Play className="w-5 h-5 text-yellow-400" />;
      case 'preparing':
        return <div className="w-5 h-5 bg-blue-500 rounded-full animate-pulse" />;
      case 'error':
        return <AlertTriangle className="w-5 h-5 text-red-500" />;
      default:
        return <MicOff className="w-5 h-5 text-gray-400" />;
    }
  };

  const getConnectionStateIcon = () => {
    switch (connectionState) {
      case 'connected':
        return <Wifi className="w-4 h-4 text-green-400" />;
      case 'connecting':
        return <div className="w-4 h-4 bg-yellow-500 rounded-full animate-pulse" />;
      case 'error':
        return <WifiOff className="w-4 h-4 text-red-500" />;
      default:
        return <WifiOff className="w-4 h-4 text-gray-400" />;
    }
  };

  const getMicrophoneStatus = () => {
    if (micPermission === 'checking') {
      return {
        icon: <div className="w-5 h-5 bg-gray-500 rounded-full animate-pulse" />,
        text: 'æ£€æµ‹éº¦å…‹é£è®¾å¤‡ä¸­...',
        canStart: false
      };
    }
    
    if (!hasAudioDevices) {
      return {
        icon: <AlertTriangle className="w-5 h-5 text-red-500" />,
        text: 'æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡',
        canStart: false
      };
    }
    
    if (micPermission === 'denied') {
      return {
        icon: <MicOff className="w-5 h-5 text-red-500" />,
        text: 'éº¦å…‹é£è®¿é—®è¢«æ‹’ç»',
        canStart: false,
        showRetryButton: true
      };
    }
    
    if (micPermission === 'prompt') {
      return {
        icon: <MicOff className="w-5 h-5 text-yellow-500" />,
        text: 'éœ€è¦éº¦å…‹é£æƒé™',
        canStart: false,
        showRetryButton: true
      };
    }
    
    if (micPermission === 'granted') {
      const level = Math.min(100, (audioLevel / 50) * 100);
      return {
        icon: (
          <div className="flex items-center space-x-2">
            <Mic className="w-5 h-5 text-green-500" />
            <div className="w-16 h-2 bg-gray-700 rounded-full overflow-hidden">
              <div 
                className="h-full bg-green-500 transition-all duration-100 rounded-full"
                style={{ width: `${level}%` }}
              />
            </div>
          </div>
        ),
        text: 'éº¦å…‹é£æ­£å¸¸å·¥ä½œ',
        canStart: true
      };
    }
    
    return {
      icon: <MicOff className="w-5 h-5 text-gray-400" />,
      text: 'æœªçŸ¥çŠ¶æ€',
      canStart: false
    };
  };

  const micStatus = getMicrophoneStatus();
  const canStart = micStatus.canStart && recordingState === 'idle';
  const isRecording = recordingState === 'recording';

  return (
    <div className="fixed inset-0 bg-gradient-to-br from-gray-900 via-gray-800 to-gray-900 overflow-hidden">
      {/* Background decorative elements */}
      <div className="absolute inset-0 overflow-hidden pointer-events-none -z-10">
        <div className="absolute top-1/4 left-1/4 w-96 h-96 bg-gradient-to-r from-red-500/10 to-orange-500/10 rounded-full blur-3xl" />
        <div className="absolute bottom-1/4 right-1/4 w-96 h-96 bg-gradient-to-r from-teal-500/10 to-cyan-500/10 rounded-full blur-3xl" />
      </div>

      <div className="relative h-full flex flex-col">
        {/* Header */}
        <div className="flex items-center justify-between p-6 border-b border-white/10">
          <div className="flex items-center space-x-4">
            <button
              onClick={() => navigate('/app/meetings')}
              className="p-2 text-gray-400 hover:text-white transition-colors rounded-lg hover:bg-white/5"
            >
              <ArrowLeft className="w-5 h-5" />
            </button>
            <div className="flex items-center space-x-3">
              {getRecordingStateIcon()}
              <h1 className="text-xl font-semibold text-white">
                {recordingState === 'idle' ? 'å®æ—¶å½•åˆ¶' :
                 recordingState === 'preparing' ? 'å‡†å¤‡ä¸­...' :
                 recordingState === 'recording' ? 'å½•åˆ¶ä¸­' :
                 recordingState === 'paused' ? 'å·²æš‚åœ' :
                 recordingState === 'stopped' ? 'å·²åœæ­¢' : 'å‡ºé”™'}
              </h1>
            </div>
          </div>
          
          <div className="flex items-center space-x-4">
            {/* Connection Status */}
            <div className="flex items-center space-x-2 text-sm text-gray-400">
              {getConnectionStateIcon()}
              <span>{connectionStatus || 'æœªè¿æ¥'}</span>
            </div>
            
            {/* Timer */}
            {hasStarted && (
              <div className="text-2xl font-mono font-bold text-red-400 flex items-center">
                {isRecording && <span className="w-3 h-3 bg-red-500 rounded-full animate-pulse mr-3" />}
                {format(elapsed)}
              </div>
            )}
            
            {/* Settings */}
            <button
              onClick={() => setShowSettings(!showSettings)}
              className="p-2 text-gray-400 hover:text-white transition-colors rounded-lg hover:bg-white/5"
            >
              <Settings className="w-5 h-5" />
            </button>
          </div>
        </div>

        {/* Error Display */}
        {error && (
          <div className="mx-6 mt-4 p-4 bg-red-500/10 border border-red-500/20 rounded-lg">
            <div className="flex items-center">
              <AlertTriangle className="w-5 h-5 text-red-400 mr-2" />
              <span className="text-red-400">{error}</span>
              <button
                onClick={() => setError(null)}
                className="ml-auto text-red-400 hover:text-red-300"
              >
                âœ•
              </button>
            </div>
          </div>
        )}

        {/* Settings Panel */}
        {showSettings && (
          <div className="mx-6 mt-4 p-4 bg-black/20 border border-white/10 rounded-lg">
            <h3 className="text-white font-medium mb-3">å½•åˆ¶è®¾ç½®</h3>
            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
              <div>
                <label className="block text-sm text-gray-400 mb-2">éº¦å…‹é£è®¾å¤‡</label>
                <select
                  value={selectedDeviceId}
                  onChange={(e) => handleDeviceChange(e.target.value)}
                  className="w-full px-3 py-2 bg-white/5 border border-white/10 rounded-lg text-white text-sm focus:outline-none focus:ring-2 focus:ring-red-500/50"
                >
                  {audioDevices.map((device) => (
                    <option key={device.deviceId} value={device.deviceId} className="bg-gray-800">
                      {device.label || `éº¦å…‹é£ ${device.deviceId.slice(0, 8)}`}
                    </option>
                  ))}
                </select>
              </div>
              <div className="flex items-center justify-between">
                <span className="text-sm text-gray-400">è‡ªåŠ¨ä¿å­˜ç¬”è®°</span>
                <button
                  onClick={() => setIsAutoSave(!isAutoSave)}
                  className={`relative inline-flex h-6 w-11 items-center rounded-full transition-colors ${
                    isAutoSave ? 'bg-green-600' : 'bg-gray-600'
                  }`}
                >
                  <span
                    className={`inline-block h-4 w-4 transform rounded-full bg-white transition-transform ${
                      isAutoSave ? 'translate-x-6' : 'translate-x-1'
                    }`}
                  />
                </button>
              </div>
            </div>
          </div>
        )}

        {/* Main Content */}
        <div className="flex-1 flex overflow-hidden">
          {/* Left Panel - Notes Editor */}
          <div className="flex-1 flex flex-col">
            {/* Title Input */}
            {!hasStarted && (
              <div className="p-6 flex justify-center">
                <input
                  value={title}
                  onChange={(e) => setTitle(e.target.value)}
                  placeholder="ä¼šè®®æ ‡é¢˜..."
                  className="w-full max-w-md px-4 py-3 bg-white/5 border border-white/10 rounded-xl text-white placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-red-500/40 focus:border-red-500/40 text-center"
                />
              </div>
            )}
            
            {hasStarted && (
              <div className="p-6 border-b border-white/10">
                <div className="flex items-center justify-between">
                  <input
                    value={title}
                    onChange={(e) => setTitle(e.target.value)}
                    placeholder="ä¼šè®®æ ‡é¢˜..."
                    className="flex-1 px-3 py-2 bg-white/5 border border-white/10 rounded-lg text-white placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-red-500/40 focus:border-red-500/40"
                  />
                  <div className="flex items-center space-x-2 ml-4">
                    <button
                      onClick={saveNotes}
                      className="p-2 text-gray-400 hover:text-white transition-colors rounded-lg hover:bg-white/5"
                      title="æ‰‹åŠ¨ä¿å­˜"
                    >
                      <Save className="w-4 h-4" />
                    </button>
                    {lastSaved && (
                      <span className="text-xs text-gray-500">
                        å·²ä¿å­˜ {lastSaved.toLocaleTimeString()}
                      </span>
                    )}
                  </div>
                </div>
              </div>
            )}

            {/* Notes Editor */}
            {hasStarted && (
              <div className="flex-1 p-6 overflow-hidden">
                <div className="h-full bg-black/20 border border-white/10 rounded-xl p-4 overflow-y-auto">
                  <div className="prose prose-invert max-w-none leading-relaxed prose-p:my-1 prose-headings:my-2 prose-h1:my-3 prose-h2:my-2 prose-h3:my-1 prose-ul:my-1 prose-ol:my-1 prose-li:my-0 prose-pre:my-2">
                    <EditorContent editor={editor} />
                  </div>
                </div>
              </div>
            )}
          </div>

          {/* Right Panel - Transcript & Controls */}
          <div className="w-96 border-l border-white/10 flex flex-col">
            {/* Microphone Status */}
            <div className="p-4 border-b border-white/10">
              <div className="flex items-center justify-between mb-3">
                <h3 className="text-white font-medium">éº¦å…‹é£çŠ¶æ€</h3>
                <Volume2 className="w-4 h-4 text-gray-400" />
              </div>
              
              <div className="flex items-center space-x-3 mb-3">
                {micStatus.icon}
                <span className="text-sm text-gray-300">{micStatus.text}</span>
              </div>
              
                {micStatus.showRetryButton && (
                  <button 
                  onClick={() => requestMicrophoneAccess()}
                  className="w-full px-3 py-2 bg-yellow-600 hover:bg-yellow-700 text-white rounded-md transition-colors text-sm"
                  >
                  é‡æ–°æˆæƒ
                  </button>
                )}
              </div>
              
            {/* Recording Controls */}
            <div className="p-4 border-b border-white/10">
              <div className="flex flex-col space-y-3">
                {recordingState === 'idle' && (
                  <button 
                    onClick={start}
                    disabled={!canStart}
                    className="w-full px-4 py-3 bg-gradient-to-r from-red-500 to-red-600 text-white rounded-lg hover:from-red-600 hover:to-red-700 transition-all shadow-lg disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center space-x-2"
                  >
                    <Mic className="w-5 h-5" />
                    <span>å¼€å§‹å½•åˆ¶</span>
                  </button>
                )}
                
                {recordingState === 'preparing' && (
                  <button 
                    disabled
                    className="w-full px-4 py-3 bg-blue-500 text-white rounded-lg opacity-50 cursor-not-allowed flex items-center justify-center space-x-2"
                  >
                    <div className="w-5 h-5 bg-white rounded-full animate-pulse" />
                    <span>å‡†å¤‡ä¸­...</span>
                  </button>
                )}
                
                {recordingState === 'recording' && (
                  <div className="space-y-2">
                    <button 
                      onClick={pause}
                      className="w-full px-4 py-3 bg-yellow-600 hover:bg-yellow-700 text-white rounded-lg transition-all flex items-center justify-center space-x-2"
                    >
                      <Play className="w-5 h-5" />
                      <span>æš‚åœ</span>
                    </button>
                    <button 
                      onClick={stop}
                      className="w-full px-4 py-3 bg-gray-600 hover:bg-gray-700 text-white rounded-lg transition-all flex items-center justify-center space-x-2"
                    >
                      <Square className="w-5 h-5" />
                      <span>åœæ­¢å½•åˆ¶</span>
                    </button>
                  </div>
                )}
                
                {recordingState === 'paused' && (
                  <div className="space-y-2">
                    <button 
                      onClick={resume}
                      className="w-full px-4 py-3 bg-green-600 hover:bg-green-700 text-white rounded-lg transition-all flex items-center justify-center space-x-2"
                    >
                      <Play className="w-5 h-5" />
                      <span>ç»§ç»­å½•åˆ¶</span>
                    </button>
                    <button 
                      onClick={stop}
                      className="w-full px-4 py-3 bg-gray-600 hover:bg-gray-700 text-white rounded-lg transition-all flex items-center justify-center space-x-2"
                    >
                      <Square className="w-5 h-5" />
                      <span>åœæ­¢å½•åˆ¶</span>
                    </button>
                  </div>
                )}
              </div>
            </div>

            {/* Transcript Display */}
            {hasStarted && (
              <div className="flex-1 flex flex-col">
                <div className="p-4 border-b border-white/10">
                  <div className="flex items-center space-x-2">
                    <MessageSquare className="w-4 h-4 text-gray-400" />
                    <h3 className="text-white font-medium">å®æ—¶è½¬å†™</h3>
                    <span className="text-xs text-gray-500">({transcripts.length})</span>
          </div>
        </div>

                <div className="flex-1 p-4 overflow-y-auto">
                  <div className="space-y-3">
                    {transcripts.length === 0 ? (
                      <div className="text-center text-gray-500 py-8">
                        <MessageSquare className="w-8 h-8 mx-auto mb-2 opacity-50" />
                        <p>ç­‰å¾…è½¬å†™ç»“æœ...</p>
                      </div>
                    ) : (
                      transcripts.map((item) => (
                        <div
                          key={item.id}
                          className={`p-3 rounded-lg ${
                            item.is_final ? 'bg-white/5 border border-white/10' : 'bg-blue-500/10 border border-blue-500/20'
                          }`}
                        >
                          <div className="flex items-start justify-between mb-1">
                            <span className="text-xs text-gray-400">
                              {item.speaker && `${item.speaker} â€¢ `}
                              {formatTimestamp(item.timestamp)}
                            </span>
                            {item.confidence && (
                              <span className="text-xs text-gray-500">
                                {Math.round(item.confidence * 100)}%
                              </span>
                            )}
                          </div>
                          <p className={`text-sm ${item.is_final ? 'text-gray-300' : 'text-blue-300'}`}>
                            {item.text}
                          </p>
                        </div>
                      ))
                    )}
                    <div ref={transcriptEndRef} />
              </div>
            </div>
          </div>
        )}
          </div>
        </div>
      </div>
    </div>
  );
};

export default LiveRecord;


